{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40aed0e2",
   "metadata": {},
   "source": [
    "# ðŸ  ðŸŽ“ Analisis Regresi pada Student Performance Dataset Menggunakan Decision Tree dan Random Forest Regression \n",
    "## ðŸŽ¯ Tujuan Proyek\n",
    "\n",
    "Proyek ini bertujuan untuk membangun dan membandingkan performa dua algoritma regresi non-linear, yaitu Decision Tree Regressor dan Random Forest Regressor, dalam memprediksi nilai median harga rumah (Median House Value) berdasarkan karakteristik demografis dan geografis wilayah di California.\n",
    "\n",
    "Dataset yang digunakan adalah Student Performance Dataset, yang berisi kombinasi data numerik dan kategorik, seperti jam belajar, tingkat kehadiran, nilai sebelumnya, jenis kelamin, tingkat pendidikan orang tua, serta faktor pendukung lainnya.\n",
    "\n",
    "## âš™ï¸ **Ruang Lingkup dan Tujuan Analisis**\n",
    "\n",
    "Analisis pada notebook ini difokuskan pada regresi non-linear, dengan tujuan untuk:\n",
    "\n",
    "Melakukan exploratory data analysis (EDA) guna memahami karakteristik dataset, termasuk pengecekan nilai kosong, duplikasi data, dan distribusi fitur numerik.\n",
    "\n",
    "Menentukan fitur (X) dan target (y), di mana target yang digunakan adalah performa siswa.\n",
    "\n",
    "Membangun dua pipeline model regresi non-linear, yaitu:\n",
    "\n",
    "Pipeline 1: Decision Tree Regressor\n",
    "\n",
    "Pipeline 2: Random Forest Regressor\n",
    "\n",
    "Membandingkan performa kedua model menggunakan:\n",
    "\n",
    "Dua metode penskalaan data: StandardScaler dan MinMaxScaler\n",
    "\n",
    "Dua metode seleksi fitur: SelectKBest dan SelectPercentile\n",
    "\n",
    "Melakukan hyperparameter tuning menggunakan GridSearchCV dengan metode Cross Validation.\n",
    "\n",
    "Mengevaluasi performa model berdasarkan metrik regresi RÂ², Mean Squared Error (MSE), Mean Absolute Error (MAE), dan Root Mean Squared Error (RMSE).\n",
    "\n",
    "## ðŸŒ³ **Alasan Pemilihan Model**\n",
    "\n",
    "Decision Tree Regressor dipilih karena kemampuannya dalam menangkap hubungan non-linear antar fitur tanpa memerlukan asumsi bentuk hubungan tertentu, serta kemudahan dalam interpretasi struktur pohon keputusan. Model ini sesuai untuk menganalisis pengaruh berbagai faktor akademik dan non-akademik terhadap performa siswa.\n",
    "\n",
    "Random Forest Regressor digunakan sebagai model ensemble yang mengombinasikan banyak decision tree untuk meningkatkan stabilitas dan akurasi prediksi. Dengan mekanisme agregasi beberapa pohon, model ini mampu mengurangi overfitting yang sering terjadi pada decision tree tunggal dan memberikan performa yang lebih baik pada data uji.\n",
    "\n",
    "## ðŸ§© **Tahapan Eksperimen**\n",
    "\n",
    "Tahapan eksperimen dalam penelitian ini dilakukan sebagai berikut:\n",
    "\n",
    "### 1 Data Understanding dan Data Cleaning\n",
    "Membaca dataset, menampilkan contoh data, informasi kolom, serta statistik deskriptif.\n",
    "Dilakukan pengecekan missing value, data duplikat, dan outlier.\n",
    "\n",
    "### 2 Data Encoding\n",
    "Mengidentifikasi fitur kategorik dan melakukan encoding (misalnya One-Hot Encoding) untuk mengubah data kategorik menjadi bentuk numerik yang dapat diproses oleh model regresi.\n",
    "\n",
    "### 3 Penentuan Fitur dan Target\n",
    "Menentukan variabel fitur (X) dan variabel target (y) berupa nilai performa siswa.\n",
    "\n",
    "### 4 Trainâ€“Test Split\n",
    "Membagi dataset menjadi data latih dan data uji dengan rasio 80:20 / 75:25 / 70:30, serta menggunakan nilai random_state sesuai ketentuan UAS.\n",
    "\n",
    "### 5 Pembangunan Pipeline Model\n",
    "Menyusun pipeline yang mencakup:\n",
    "    + Scaling (StandardScaler dan MinMaxScaler)\n",
    "    + Feature selection (SelectKBest dan SelectPercentile)\n",
    "    + Model regresi (Decision Tree dan Random Forest)\n",
    "\n",
    "### 6 Hyperparameter Tuning dan Cross Validation\n",
    "Melakukan pencarian parameter terbaik menggunakan GridSearchCV dengan metode Cross Validation.\n",
    "\n",
    "### 7 Evaluasi dan Visualisasi\n",
    "Mengevaluasi performa model menggunakan RÂ², MSE, MAE, dan RMSE, serta menampilkan visualisasi:\n",
    "    * Scatterplot matrix antar fitur\n",
    "    * Plot residual data training dan testing\n",
    "    * Plot hubungan fitur terhadap target\n",
    "    * Perbandingan nilai prediksi dan aktual pada data uji\n",
    "\n",
    "### 8 Pemilihan Model Terbaik\n",
    "Menentukan satu model regresi terbaik dan mengekspornya dalam format Pickle (.pkl) untuk digunakan pada aplikasi Streamlit.\n",
    "\n",
    "## ðŸ“Š **Hasil yang Diharapkan**\n",
    "\n",
    "Melalui rangkaian eksperimen yang dilakukan, hasil yang diharapkan dari notebook ini adalah sebagai berikut:\n",
    "\n",
    "Diperoleh model regresi non-linear terbaik dengan nilai RÂ² tertinggi serta nilai error (MSE, MAE, dan RMSE) terendah.\n",
    "\n",
    "Teridentifikasi fitur-fitur paling relevan yang berkontribusi signifikan dalam memprediksi Median House Value pada dataset California Housing.\n",
    "\n",
    "Diperoleh perbandingan performa yang jelas antara Decision Tree Regressor dan Random Forest Regressor, baik dari sisi akurasi prediksi maupun stabilitas model.\n",
    "\n",
    "Terlihat bahwa Random Forest Regressor secara umum diharapkan memiliki performa lebih baik dibandingkan Decision Tree Regressor, terutama dalam mengurangi overfitting dan meningkatkan generalisasi model.\n",
    "\n",
    "Hasil evaluasi dan visualisasi dapat menjadi dasar pemilihan model terbaik yang selanjutnya digunakan dalam aplikasi Streamlit sebagai implementasi akhir projek UAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc03fed6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ§® IMPORT LIBRARY â€” Regresi Non-Linear (UAS ML)\n",
    "# ============================================================\n",
    "\n",
    "# ðŸ“¦ Manipulasi Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ðŸ“Š Visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ðŸ”§ Pembagian Data & Hyperparameter Tuning\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "\n",
    "# âš™ï¸ Pra-pemrosesan & Seleksi Fitur\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_regression\n",
    "\n",
    "# ðŸ¤– Model Regresi Non-Linear\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# ðŸ§© Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ðŸ“ˆ Evaluasi Model Regresi\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error\n",
    ")\n",
    "\n",
    "# ðŸ” Utilitas\n",
    "import time\n",
    "\n",
    "np.random.seed(98)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85066a55",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f031b8d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df_house = pd.read_csv(\"dataset/Student_Performance.csv\", header=0)\n",
    "\n",
    "df_house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c38e6e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Info cepat tentang kolom & tipe datanya\n",
    "print(\"Jumlah baris, kolom:\", df_house.shape)    \n",
    "print(\"\\nTipe data:\")\n",
    "print(df_house.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9bcb9a",
   "metadata": {},
   "source": [
    "## PEMBERSIHAN DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8356700",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Cek jumlah nilai kosong per kolom\n",
    "print(\"Jumlah nilai kosong per Kolom:\\n\", df_house.isnull().sum())\n",
    "missing_values = df_house.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0331ba0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Penanganan missing value (jika ada)\n",
    "if missing_values.sum() > 0:\n",
    "    for col in df_house.select_dtypes(include=[np.number]).columns:\n",
    "        median_val = df_house[col].median()\n",
    "        df_house[col].fillna(median_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e37510",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3) Validasi ulang\n",
    "print(\"\\nSetelah inputasi, nilai kosong per kolom:\\n\", df_house.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da97f16",
   "metadata": {},
   "source": [
    "### **Pembersihan Data (Bagian 3): Cek & Hapus Duplikat**\n",
    "- Data yang **kembar** dapat merusak evaluasi model.\n",
    "- Kita cek duplikat lalu **drop** agar setiap baris unik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358550fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "before = df_house.shape\n",
    "dupes = df_house[df_house.duplicated(keep=False)]\n",
    "print(f\"Jumlah baris duplikat (terhitung ganda): {dupes.shape[0]}\")\n",
    "df_house2 = df_house.drop_duplicates(keep='first')\n",
    "print(\"Bentuk data sebelum/ setelah hapus duplikat:\", before, \"->\", df_house2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98395a26",
   "metadata": {},
   "source": [
    "### **Pembersihan Data (Bagian 4): Cek Outlier**\n",
    "- Data yang **Outlier** dapat merusak evaluasi model.\n",
    "- Kenapa tidak dihapus? karena itu adalah fenomena nyata dan **Penting** untuk klasifikasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264d272",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Data Checking: Outlier (IQR)\n",
    "# =========================\n",
    "numeric_cols = df_house.select_dtypes(include=np.number).columns\n",
    "\n",
    "print(\"Pengecekan outlier menggunakan metode IQR:\\n\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = df_house[col].quantile(0.25)\n",
    "    Q3 = df_house[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outlier_count = ((df_house[col] < lower_bound) |\n",
    "                     (df_house[col] > upper_bound)).sum()\n",
    "\n",
    "    print(f\"{col}: {outlier_count} outlier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47015c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Data Preparation: Outlier Handling (Capping / Winsorization)\n",
    "# =========================\n",
    "\n",
    "df_house3 = df_house2.copy()  # df_house2 = hasil drop_duplicates sebelumnya\n",
    "\n",
    "numeric_cols = df_house3.select_dtypes(include=np.number).columns\n",
    "\n",
    "# (opsional) jika target ada di dataset, jangan ikut dicapping\n",
    "# ganti 'Performance Index' sesuai nama target kamu\n",
    "target_col = 'Performance Index'  # <-- UBAH sesuai kolom target\n",
    "numeric_features = [c for c in numeric_cols if c != target_col]\n",
    "\n",
    "before_shape = df_house3.shape\n",
    "\n",
    "for col in numeric_features:\n",
    "    Q1 = df_house3[col].quantile(0.25)\n",
    "    Q3 = df_house3[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    # capping (winsorize)\n",
    "    df_house3[col] = np.clip(df_house3[col], lower, upper)\n",
    "\n",
    "print(\"Bentuk data sebelum:\", before_shape)\n",
    "print(\"Bentuk data sesudah :\", df_house3.shape)\n",
    "\n",
    "# Validasi ulang jumlah outlier setelah capping\n",
    "print(\"\\nPengecekan outlier (IQR) setelah capping:\\n\")\n",
    "for col in numeric_features:\n",
    "    Q1 = df_house3[col].quantile(0.25)\n",
    "    Q3 = df_house3[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((df_house3[col] < (Q1 - 1.5 * IQR)) | (df_house3[col] > (Q3 + 1.5 * IQR))).sum()\n",
    "    print(f\"{col}: {outliers} outlier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c1869",
   "metadata": {},
   "source": [
    "### **Pembagian Data: Train/Test Split**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b952d9",
   "metadata": {},
   "source": [
    "###  **Encode Label**\n",
    "\n",
    "- **Tujuan:** Mengubah kolom `Extracurricular Activities` dari huruf menjadi angka agar bisa diproses oleh model ML.  \n",
    "  - `Yes` â†’ 1 (**mengikuti extracurricular**)  \n",
    "  - `No` â†’ 0 (**tidak mengikuti extracurricular**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ceb62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Mengubah label Extracurricular Activities dari huruf menjadi angka:\n",
    "df_house3['Extracurricular Activities'] = df_house3['Extracurricular Activities'].map({'Yes': 1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99d5d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Menentukan X sebagai fitur (semua kolom kecuali Performance Index)\n",
    "X = df_house3.drop(columns=['Performance Index'])\n",
    "\n",
    "# Menentukan y sebagai target (kolom Performance Index)\n",
    "y = df_house3['Performance Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68255ff8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=98\n",
    ")\n",
    "\n",
    "print(\"Ukuran X_train, X_test :\", X_train.shape, X_test.shape)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=98\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d19652",
   "metadata": {},
   "source": [
    "##  Membangun Model Regresi Non-Linear (Decision Tree & Random Forest) dengan Pipeline + GridSearchCV ###\n",
    "Pada bagian ini, kita akan membangun dan membandingkan dua model regresi non-linear berbasis pohon, yaitu Decision Tree Regressor (DTR) dan Random Forest Regressor (RFR). Kedua algoritma ini mampu menangkap pola hubungan fiturâ€“target yang kompleks tanpa mengasumsikan hubungan linear.\n",
    "\n",
    "##  Konsep Singkat Model Berbasis Pohon (Tree-Based Regression) ##\n",
    "Decision Tree Regressor bekerja dengan membagi data secara berulang berdasarkan aturan (split) pada fitur tertentu untuk meminimalkan error prediksi pada setiap node. Model ini mudah diinterpretasikan, tetapi dapat overfitting jika kedalaman pohon terlalu besar.\n",
    "\n",
    "Random Forest Regressor adalah model ensemble yang menggabungkan banyak decision tree dengan teknik bootstrap sampling dan pemilihan fitur acak. Pendekatan ini biasanya menghasilkan model yang lebih stabil dan akurat karena mampu mengurangi overfitting yang sering terjadi pada decision tree tunggal.\n",
    "\n",
    "##  Alur Pipeline ##\n",
    "\n",
    "### 1 Scaling (StandardScaler vs MinMaxScaler) ###\n",
    "Scaling disertakan untuk memenuhi ketentuan eksperimen UAS dan menjaga konsistensi pipeline, meskipun model berbasis pohon umumnya tidak sensitif terhadap skala fitur.\n",
    "\n",
    "### 2 Feature Selection (SelectKBest vs SelectPercentile) ###\n",
    "Tahap ini digunakan untuk memilih fitur yang paling relevan terhadap target regresi:\n",
    "- SelectKBest: memilih k fitur terbaik\n",
    "- SelectPercentile: memilih persentase fitur terbaik (p%)\n",
    "- Skor seleksi fitur menggunakan metode f_regression, karena sesuai untuk kasus regresi (target numerik).\n",
    "\n",
    "### 3 Model (DecisionTreeRegressor / RandomForestRegressor) ###\n",
    "Parameter yang diuji melalui GridSearchCV meliputi:\n",
    "Decision Tree Regressor:\n",
    "- max_depth: kedalaman maksimum pohon\n",
    "- min_samples_split: minimum sampel untuk membagi node\n",
    "- min_samples_leaf: minimum sampel pada leaf\n",
    "- random_state: menjaga reprodusibilitas\n",
    "Random Forest Regressor:\n",
    "- n_estimators: jumlah pohon dalam forest\n",
    "- max_depth, min_samples_split, min_samples_leaf\n",
    "- max_features: jumlah fitur yang dipertimbangkan saat split\n",
    "- random_state: menjaga reprodusibilitas\n",
    "\n",
    "### Tujuan GridSearchCV ###\n",
    "\n",
    "Melakukan pencarian otomatis kombinasi parameter terbaik untuk menghasilkan model dengan performa optimal menggunakan K-Fold Cross Validation (mis. 5-fold).\n",
    "Evaluasi utama dilakukan menggunakan RÂ², serta dilengkapi metrik error MSE, MAE, dan RMSE untuk melihat seberapa besar kesalahan prediksi model.\n",
    "\n",
    "Output yang Diharapkan dari Cell Ini\n",
    "- Model Decision Tree Regressor terbaik beserta parameter optimalnya\n",
    "- Model Random Forest Regressor terbaik beserta parameter optimalnya  \n",
    "- Waktu komputasi total untuk masing-masing GridSearchCV\n",
    "- Perbandingan performa model berdasarkan RÂ², MSE, MAE, RMSE serta jumlah fitur terbaik yang    terpilih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1ac84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Pipeline Decision Tree Regressor (Regresi) + GridSearchCV\n",
    "# ==============================================================\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import time\n",
    "\n",
    "# Pipeline dasar (scaler -> selector -> regressor)\n",
    "pipe_dt = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # akan digrid: StandardScaler / MinMaxScaler\n",
    "    ('selector', SelectKBest(score_func=f_regression)),  # akan digrid: KBest / Percentile\n",
    "    ('reg', DecisionTreeRegressor(random_state=98)),\n",
    "])\n",
    "\n",
    "param_grid_dt = [\n",
    "    # ---- SelectKBest ----\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'selector': [SelectKBest(score_func=f_regression)],\n",
    "        'selector__k': [2, 4, 'all'],  # sesuaikan dengan jumlah fitur kamu\n",
    "        'reg__max_depth': [None, 3, 5, 10],\n",
    "        'reg__min_samples_split': [2, 5, 10],\n",
    "        'reg__min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "    # ---- SelectPercentile ----\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'selector': [SelectPercentile(score_func=f_regression)],\n",
    "        'selector__percentile': [50, 70, 100],\n",
    "        'reg__max_depth': [None, 3, 5, 10],\n",
    "        'reg__min_samples_split': [2, 5, 10],\n",
    "        'reg__min_samples_leaf': [1, 2, 4],\n",
    "    }\n",
    "]\n",
    "\n",
    "# CV untuk regresi (bukan stratified)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=98)\n",
    "\n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=pipe_dt,\n",
    "    param_grid=param_grid_dt,\n",
    "    cv=cv,\n",
    "    scoring='r2',     # evaluasi utama UAS\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nâœ… Best Parameters (Decision Tree Regressor):\", grid_dt.best_params_)\n",
    "print(\"âœ… Best CV RÂ²:\", grid_dt.best_score_)\n",
    "print(f\"GridSearch Decision Tree selesai dalam {time.time() - start:.2f} detik\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf4a30",
   "metadata": {},
   "source": [
    "## Membangun Model Random Forest Regressor dengan Pipeline + GridSearchCV\n",
    "\n",
    "Pada bagian ini, kita akan membangun model Random Forest Regressor (RFR) â€” algoritma regresi non-linear berbasis ensemble yang menggabungkan banyak decision tree untuk menghasilkan prediksi yang lebih stabil dan akurat. Model ini cocok digunakan untuk studi kasus regresi seperti prediksi performa siswa (target numerik) berdasarkan berbagai fitur akademik dan non-akademik.\n",
    "\n",
    "## Konsep Singkat Random Forest Regression\n",
    "\n",
    "Random Forest Regressor bekerja dengan membangun banyak decision tree menggunakan teknik bootstrap sampling (mengambil sampel acak dari data latih) dan menggabungkan prediksi setiap pohon (umumnya dengan rata-rata untuk regresi).\n",
    "Selain itu, pada setiap split, Random Forest hanya mempertimbangkan subset fitur secara acak (feature randomness) sehingga model menjadi lebih robust.\n",
    "\n",
    "Ciri utama:\n",
    "\n",
    "- Mampu menangkap pola non-linear dan interaksi antar fitur.\n",
    "\n",
    "- Lebih stabil dibanding Decision Tree tunggal karena hasilnya merupakan gabungan banyak pohon.\n",
    "\n",
    "- Cenderung lebih tahan overfitting, tetapi tetap perlu tuning parameter agar tidak terlalu kompleks dan lambat.\n",
    "\n",
    "Alur Pipeline\n",
    "## 1) Scaling (MinMaxScaler vs StandardScaler)\n",
    "\n",
    "Scaling tetap disertakan untuk memenuhi ketentuan eksperimen UAS dan menjaga konsistensi pipeline, meskipun model berbasis pohon umumnya tidak sensitif terhadap skala fitur. Dua metode scaling dibandingkan:\n",
    "\n",
    "- StandardScaler: menstandarkan data (mean = 0, std = 1).\n",
    "\n",
    "- MinMaxScaler: menormalisasi data ke rentang [0, 1].\n",
    "\n",
    "## 2) Feature Selection (SelectKBest vs SelectPercentile)\n",
    "\n",
    "- Digunakan untuk memilih fitur yang paling relevan terhadap target regresi:\n",
    "\n",
    "- SelectKBest: memilih k fitur terbaik.\n",
    "\n",
    "- SelectPercentile: memilih persentase fitur terbaik (p%).\n",
    "Fungsi skor yang digunakan adalah f_regression, karena sesuai untuk hubungan fitur numerik dengan target numerik.\n",
    "\n",
    "## 3) Model (RandomForestRegressor)\n",
    "\n",
    "- Parameter utama yang diuji melalui GridSearchCV antara lain:\n",
    "\n",
    "- n_estimators: jumlah pohon dalam forest.\n",
    "\n",
    "- max_depth: kedalaman maksimum setiap pohon (kontrol kompleksitas).\n",
    "\n",
    "- min_samples_split: minimum sampel untuk melakukan split.\n",
    "\n",
    "- min_samples_leaf: minimum sampel yang harus ada pada leaf.\n",
    "\n",
    "- max_features: jumlah fitur yang dipertimbangkan saat melakukan split.\n",
    "\n",
    "- random_state: menjaga konsistensi hasil eksperimen.\n",
    "\n",
    "## Tujuan GridSearchCV\n",
    "\n",
    "Melakukan pencarian kombinasi parameter terbaik untuk mendapatkan model Random Forest yang paling optimal dan stabil, dengan evaluasi menggunakan 5-Fold Cross Validation (KFold) karena kasus ini merupakan regresi (target kontinu).\n",
    "\n",
    "- Metrik evaluasi utama yang digunakan adalah:\n",
    "\n",
    "- RÂ² (R-Squared) sebagai skor utama,\n",
    "serta metrik error tambahan:\n",
    "\n",
    "- MSE, MAE, dan RMSE untuk mengukur besar kesalahan prediksi.\n",
    "\n",
    "# Output dari Tahap Ini\n",
    "\n",
    "## Output yang diharapkan dari tahap pemodelan ini meliputi:\n",
    "\n",
    "- Model Random Forest Regressor terbaik dengan parameter hasil optimasi GridSearchCV,\n",
    "\n",
    "- Skor RÂ² rata-rata cross validation terbaik,\n",
    "\n",
    "- Daftar fitur terpilih dari feature selection pada konfigurasi terbaik,\n",
    "\n",
    "- Evaluasi pada data uji berupa RÂ², MSE, MAE, RMSE,\n",
    "\n",
    "- Visualisasi yang mendukung analisis model (residual plot, prediksi vs aktual, dan visualisasi lain sesuai ketentuan UAS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5da92e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Pipeline Random Forest Regressor (UAS Regresi)\n",
    "# ==============================================================\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('selector', SelectKBest(score_func=f_regression)),\n",
    "    ('reg', RandomForestRegressor(random_state=98))\n",
    "])\n",
    "\n",
    "param_grid_rf = [\n",
    "    # --- SelectKBest ---\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'selector': [SelectKBest(score_func=f_regression)],\n",
    "        'selector__k': [2, 4, 'all'],   # sesuaikan dengan jumlah fitur kamu\n",
    "        'reg__n_estimators': [100, 200],\n",
    "        'reg__max_depth': [None, 5, 10],\n",
    "        'reg__min_samples_split': [2, 5, 10],\n",
    "        'reg__min_samples_leaf': [1, 2, 4],\n",
    "        'reg__max_features': ['sqrt', 0.8, 1.0]\n",
    "    },\n",
    "    # --- SelectPercentile ---\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'selector': [SelectPercentile(score_func=f_regression)],\n",
    "        'selector__percentile': [50, 70, 100],\n",
    "        'reg__n_estimators': [100, 200],\n",
    "        'reg__max_depth': [None, 5, 10],\n",
    "        'reg__min_samples_split': [2, 5, 10],\n",
    "        'reg__min_samples_leaf': [1, 2, 4],\n",
    "        'reg__max_features': ['sqrt', 0.8, 1.0]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=98)\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=cv,\n",
    "    scoring='r2',      # metrik utama regresi\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nâœ… Best Parameters (Random Forest Regressor):\", grid_rf.best_params_)\n",
    "print(\"âœ… Best CV RÂ²:\", grid_rf.best_score_)\n",
    "print(f\"GridSearch Random Forest selesai dalam {time.time() - start:.2f} detik\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95f75d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ambil model terbaik dari GridSearch\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Hitung metrik regresi\n",
    "metrics_rf = {\n",
    "    \"R2\": r2_score(y_test, y_pred_rf),\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_rf),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_rf),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "}\n",
    "\n",
    "print(\"Kombinasi model terbaik (Random Forest):\", best_rf)\n",
    "print(\"CV score terbaik (RÂ²):\", grid_rf.best_score_)\n",
    "\n",
    "print(\"\\nðŸ“Š Random Forest Regression Performance (Test Set):\")\n",
    "for k, v in metrics_rf.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Tampilkan fitur terpilih dari feature selection\n",
    "selector = best_rf.named_steps['selector']\n",
    "if hasattr(selector, 'get_support'):\n",
    "    mask = selector.get_support()\n",
    "    selected = np.array(X.columns)[mask]\n",
    "    print(\"\\nFitur terbaik (terpilih):\", selected)\n",
    "\n",
    "# =========================\n",
    "# Visualisasi Wajib (Regresi)\n",
    "# =========================\n",
    "\n",
    "# 1) Prediksi vs Aktual (20 data test pertama)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.array(y_test)[:20], label=\"Aktual\", marker='o')\n",
    "plt.plot(y_pred_rf[:20], label=\"Prediksi\", marker='x')\n",
    "plt.title(\"Prediksi vs Aktual â€” Random Forest (20 Data Test Pertama)\")\n",
    "plt.xlabel(\"Index Sampel\")\n",
    "plt.ylabel(\"Nilai Target\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2) Residual Plot (Test)\n",
    "residuals = np.array(y_test) - y_pred_rf\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_pred_rf, residuals, alpha=0.7)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title(\"Residual Plot â€” Random Forest Regressor\")\n",
    "plt.xlabel(\"Nilai Prediksi\")\n",
    "plt.ylabel(\"Residual (Aktual - Prediksi)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfaf6f8",
   "metadata": {},
   "source": [
    "## VISUALISASI PERBANDINGAN MODEL ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693b4a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# ðŸŽ¨ Visualisasi Gabungan: Decision Tree vs Random Forest (Regresi)\n",
    "# ==============================================================\n",
    "\n",
    "# Pastikan sudah punya:\n",
    "# y_pred_dt  -> prediksi Decision Tree pada X_test\n",
    "# y_pred_rf  -> prediksi Random Forest pada X_test\n",
    "\n",
    "metrics_dt = {\n",
    "    \"R2\": r2_score(y_test, y_pred_dt),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_dt),\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_dt),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "}\n",
    "\n",
    "metrics_rf = {\n",
    "    \"R2\": r2_score(y_test, y_pred_rf),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_rf),\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_rf),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "}\n",
    "\n",
    "df_compare = pd.DataFrame([metrics_dt, metrics_rf], index=[\"Decision Tree\", \"Random Forest\"])\n",
    "display(df_compare)\n",
    "\n",
    "# Buat figure dengan 3 subplot (1 baris, 3 kolom)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(18, 4))\n",
    "\n",
    "# 1) Prediksi vs Aktual (Decision Tree)\n",
    "ax1.plot(np.array(y_test)[:20], label=\"Aktual\", marker='o')\n",
    "ax1.plot(np.array(y_pred_dt)[:20], label=\"Prediksi\", marker='x')\n",
    "ax1.set_title(\"Decision Tree â€” Prediksi vs Aktual (20 data)\")\n",
    "ax1.set_xlabel(\"Index Sampel\")\n",
    "ax1.set_ylabel(\"Nilai Target\")\n",
    "ax1.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "ax1.legend()\n",
    "\n",
    "# 2) Prediksi vs Aktual (Random Forest)\n",
    "ax2.plot(np.array(y_test)[:20], label=\"Aktual\", marker='o')\n",
    "ax2.plot(np.array(y_pred_rf)[:20], label=\"Prediksi\", marker='x')\n",
    "ax2.set_title(\"Random Forest â€” Prediksi vs Aktual (20 data)\")\n",
    "ax2.set_xlabel(\"Index Sampel\")\n",
    "ax2.set_ylabel(\"Nilai Target\")\n",
    "ax2.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "ax2.legend()\n",
    "\n",
    "# 3) Grafik Bar Perbandingan Metrik\n",
    "cols = df_compare.columns.tolist()\n",
    "x = np.arange(len(cols))\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar(x - width/2, df_compare.loc[\"Decision Tree\"], width, label=\"Decision Tree\")\n",
    "ax3.bar(x + width/2, df_compare.loc[\"Random Forest\"], width, label=\"Random Forest\")\n",
    "\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(cols)\n",
    "ax3.set_ylabel(\"Score\")\n",
    "ax3.set_title(\"Perbandingan Kinerja Model (Regresi)\")\n",
    "ax3.legend()\n",
    "ax3.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f6092",
   "metadata": {},
   "source": [
    "## Feature dengan score tertinggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12652c89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Feature Importance â€” Decision Tree\n",
    "# =========================\n",
    "\n",
    "selector_dt = grid_dt.best_estimator_.named_steps['selector']\n",
    "\n",
    "feature_scores_dt = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Score': selector_dt.scores_\n",
    "}).sort_values(by='Score', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Feature Importance (Decision Tree - f_regression):\")\n",
    "display(feature_scores_dt)\n",
    "# =========================\n",
    "# Feature Importance â€” Random Forest\n",
    "# =========================\n",
    "\n",
    "rf_model = grid_rf.best_estimator_.named_steps['reg']\n",
    "\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Feature Importance (Random Forest):\")\n",
    "display(feature_importance_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f7cf2",
   "metadata": {},
   "source": [
    "## Model Terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447faba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Hitung RÂ² pada data test\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Bandingkan model\n",
    "if r2_rf >= r2_dt:\n",
    "    best_model = best_rf\n",
    "    best_name = \"RandomForestRegressor\"\n",
    "else:\n",
    "    best_model = best_dt\n",
    "    best_name = \"DecisionTreeRegressor\"\n",
    "\n",
    "# Simpan model terbaik\n",
    "with open(f\"model/BestModel_REG_{best_name}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"\\nâœ… Model terbaik: {best_name}\")\n",
    "print(f\"âœ… RÂ² Decision Tree : {r2_dt:.4f}\")\n",
    "print(f\"âœ… RÂ² Random Forest : {r2_rf:.4f}\")\n",
    "print(f\"âœ… File tersimpan sebagai: BestModel_REG_{best_name}.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
